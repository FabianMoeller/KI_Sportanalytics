{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuronalNetVector(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(NeuronalNetVector, self).__init__()\n",
    "            self.lin1 = nn.Linear(8,15)\n",
    "            #Größer als 8,3333\n",
    "            #Kleiner als 16\n",
    "            self.lin2 = nn.Linear(15,15)\n",
    "            self.lin3 = nn.Linear(15,3)\n",
    "        def forward(self,x):\n",
    "            x = self.lin1(x)\n",
    "            x = F.relu(x)\n",
    "            x = F.relu(self.lin2(x))\n",
    "            x = F.relu(self.lin3(x))\n",
    "            x = F.softmax(x,dim=0)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Die Tore der einzelnen Mannschaften pro Spiel aus den matches in eine Liste schreiben\n",
    "def inputValuesVector(gameList, df_stats,inputList):\n",
    "    for match in gameList:\n",
    "        homeTeam = match.iat[0,0]\n",
    "        awayTeam = match.iat[0,1]\n",
    "        input_values= df_stats[df_stats['HomeTeam']==homeTeam]\n",
    "        input_values= input_values[input_values['AwayTeam']==awayTeam]\n",
    "        input_values= input_values.reset_index(drop=True)\n",
    "        input_values = input_values[:-1]\n",
    "        inputList.append(input_values.loc[:,['FTHG','FTAG']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Methode um aus einer Liste eine Tensorliste mit Floatwerten generieren\n",
    "def dfToTensor(dfList, tensorList):\n",
    "    for df in dfList:\n",
    "        tensor = torch.FloatTensor(df.values).view(8)\n",
    "        tensorList.append(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfToTensor_forTarget(dfList, tensorList):\n",
    "    for df in dfList:\n",
    "        tensor = torch.FloatTensor(df).view(3)\n",
    "        tensorList.append(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outputvalues generieren, bei einem target als Vector\n",
    "def targetValuesVector(gameList, df_stats,targetList):\n",
    "    for match in gameList:\n",
    "        homeTeam = match.iat[0,0]\n",
    "        awayTeam = match.iat[0,1]\n",
    "        target_values= df_stats[df_stats['HomeTeam']==homeTeam]\n",
    "        target_values= target_values[target_values['AwayTeam']==awayTeam]\n",
    "        target_values= target_values.reset_index(drop=True)\n",
    "        target_values = target_values.tail(1)\n",
    "        target_values = target_values.loc[:,['FTHG','FTAG']]\n",
    "        homegoals = target_values.loc[:,['FTHG']].iloc[0]['FTHG']\n",
    "        awaygoals = target_values.loc[:,['FTAG']].iloc[0]['FTAG']\n",
    "        if homegoals > awaygoals:\n",
    "            df_target=[[1.,0.,0.]]\n",
    "        if homegoals == awaygoals:\n",
    "            df_target=[[0.,1.,0.]]\n",
    "        if homegoals < awaygoals:\n",
    "            df_target=[[0.,0.,1.]]\n",
    "        targetList.append(df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pfade Fabian\n",
    "#/Users/fabian-maltemoller/Developer/Ki/KI_Daten/09_10-13_14.csv\n",
    "#/Users/fabian-maltemoller/Developer/Ki/KI_Daten/10_11-14_15.csv\n",
    "#/Users/fabian-maltemoller/Developer/Ki/KI_Daten/11_12-15_16.csv\n",
    "#/Users/fabian-maltemoller/Developer/Ki/KI_Daten/12_13-16_17.csv\n",
    "#/Users/fabian-maltemoller/Developer/Ki/KI_Daten/13_14-17_18.csv\n",
    "#/Users/fabian-maltemoller/Developer/Ki/KI_Daten/14_15-18_19.csv\n",
    "\n",
    "#C:\\\\Users\\\\dusti\\\\iCloudDrive\\\\Studium WI\\\\WS2019\\\\KI\\\\csvData\\\\09_10-13_14.csv\n",
    "#C:\\\\Users\\\\dusti\\\\iCloudDrive\\\\Studium WI\\\\WS2019\\\\KI\\\\csvData\\\\10_11-14_15.csv\n",
    "#C:\\\\Users\\\\dusti\\\\iCloudDrive\\\\Studium WI\\\\WS2019\\\\KI\\\\csvData\\\\11_12-15_16.csv\n",
    "#C:\\\\Users\\\\dusti\\\\iCloudDrive\\\\Studium WI\\\\WS2019\\\\KI\\\\csvData\\\\12_13-16_17.csv\n",
    "#C:\\\\Users\\\\dusti\\\\iCloudDrive\\\\Studium WI\\\\WS2019\\\\KI\\\\csvData\\\\13_14-17_18.csv\n",
    "#C:\\\\Users\\\\dusti\\\\iCloudDrive\\\\Studium WI\\\\WS2019\\\\KI\\\\csvData\\\\14_15-18_19.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorInputTarget(path,inputListe,targetListe):\n",
    "    topTeams = pd.read_csv(path, sep=';')\n",
    "    df = pd.DataFrame(topTeams, columns = ['Date','HomeTeam','AwayTeam','FTHG','FTAG','FTR'])\n",
    "    df_names = df.drop_duplicates(['HomeTeam','AwayTeam'],keep = 'last')\n",
    "    df_names = df_names[['HomeTeam','AwayTeam']]\n",
    "    gameListe = []\n",
    "    for row in df_names.itertuples():\n",
    "        data = [[row.HomeTeam,row.AwayTeam]]\n",
    "        gameListe.append(pd.DataFrame(data))\n",
    "    inputValuesVector(gameListe, df,inputListe)\n",
    "    targetValuesVector(gameListe,df,targetListe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputList_0910_1314_Vector = []\n",
    "targetList_0910_1314_Vector = []\n",
    "vectorInputTarget('/Users/fabian-maltemoller/Developer/Ki/KI_Daten/09_10-13_14.csv',inputList_0910_1314_Vector,targetList_0910_1314_Vector)\n",
    "#vectorInputTarget('C:\\\\Users\\\\dusti\\\\iCloudDrive\\\\Studium WI\\\\WS2019\\\\KI\\\\csvData\\\\09_10-13_14.csv',inputList_0910_1314,outputList_0910_1314)\n",
    "\n",
    "inputList_1011_1415_Vector = []\n",
    "targetList_1011_1415_Vector = []\n",
    "vectorInputTarget('/Users/fabian-maltemoller/Developer/Ki/KI_Daten/10_11-14_15.csv',inputList_1011_1415_Vector,targetList_1011_1415_Vector)\n",
    "#vectorInputTarget('C:\\\\Users\\\\dusti\\\\iCloudDrive\\\\Studium WI\\\\WS2019\\\\KI\\\\csvData\\\\10_11-14_15.csv',inputList_1011_1415,outputList_1011_1415)\n",
    "\n",
    "inputList_1112_1516_Vector = []\n",
    "targetList_1112_1516_Vector = []\n",
    "vectorInputTarget('/Users/fabian-maltemoller/Developer/Ki/KI_Daten/11_12-15_16.csv',inputList_1112_1516_Vector,targetList_1112_1516_Vector)\n",
    "#vectorInputTarget('C:\\\\Users\\\\dusti\\\\iCloudDrive\\\\Studium WI\\\\WS2019\\\\KI\\\\csvData\\\\11_12-15_16.csv',inputList_1112_1516,outputList_1112_1516)\n",
    "\n",
    "inputList_1213_1617_Vector = []\n",
    "targetList_1213_1617_Vector = []\n",
    "vectorInputTarget('/Users/fabian-maltemoller/Developer/Ki/KI_Daten/12_13-16_17.csv',inputList_1213_1617_Vector,targetList_1213_1617_Vector)\n",
    "#vectorInputTarget('C:\\\\Users\\\\dusti\\\\iCloudDrive\\\\Studium WI\\\\WS2019\\\\KI\\\\csvData\\\\12_13-16_17.csv',inputList_1213_1617,outputList_1213_1617)\n",
    "\n",
    "inputList_1314_1718_Vector = []\n",
    "targetList_1314_1718_Vector = []\n",
    "vectorInputTarget('/Users/fabian-maltemoller/Developer/Ki/KI_Daten/13_14-17_18.csv',inputList_1314_1718_Vector,targetList_1314_1718_Vector)\n",
    "#vectorInputTarget('C:\\\\Users\\\\dusti\\\\iCloudDrive\\\\Studium WI\\\\WS2019\\\\KI\\\\csvData\\\\13_14-17_18.csv',inputList_1314_1718,outputList_1314_1718)\n",
    "\n",
    "inputList_1415_1819_Vector = []\n",
    "targetList_1415_1819_Vector = []\n",
    "vectorInputTarget('/Users/fabian-maltemoller/Developer/Ki/KI_Daten/14_15-18_19.csv',inputList_1415_1819_Vector,targetList_1415_1819_Vector)\n",
    "#vectorInputTarget('C:\\\\Users\\\\dusti\\\\iCloudDrive\\\\Studium WI\\\\WS2019\\\\KI\\\\csvData\\\\14_15-18_19.csv',inputList_1415_1819,outputList_1415_1819)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "14\n",
      "32\n",
      "46\n",
      "54\n",
      "63\n",
      "85\n",
      "92\n",
      "97\n",
      "109\n",
      "116\n"
     ]
    }
   ],
   "source": [
    "#Leere Dataframes löschen\n",
    "for i in range(len(inputList_1415_1819_Vector)):\n",
    "    if inputList_1415_1819_Vector[i].empty:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n",
      "110\n"
     ]
    }
   ],
   "source": [
    "inputList_1415_1819_Vector.pop(11)\n",
    "inputList_1415_1819_Vector.pop(13)\n",
    "inputList_1415_1819_Vector.pop(30)\n",
    "inputList_1415_1819_Vector.pop(43)\n",
    "inputList_1415_1819_Vector.pop(50)\n",
    "inputList_1415_1819_Vector.pop(58)\n",
    "inputList_1415_1819_Vector.pop(79)\n",
    "inputList_1415_1819_Vector.pop(85)\n",
    "inputList_1415_1819_Vector.pop(89)\n",
    "inputList_1415_1819_Vector.pop(100)\n",
    "inputList_1415_1819_Vector.pop(106)\n",
    "\n",
    "targetList_1415_1819_Vector.pop(11)\n",
    "targetList_1415_1819_Vector.pop(13)\n",
    "targetList_1415_1819_Vector.pop(30)\n",
    "targetList_1415_1819_Vector.pop(43)\n",
    "targetList_1415_1819_Vector.pop(50)\n",
    "targetList_1415_1819_Vector.pop(58)\n",
    "targetList_1415_1819_Vector.pop(79)\n",
    "targetList_1415_1819_Vector.pop(85)\n",
    "targetList_1415_1819_Vector.pop(89)\n",
    "targetList_1415_1819_Vector.pop(100)\n",
    "targetList_1415_1819_Vector.pop(106)\n",
    "\n",
    "print(len(inputList_1415_1819_Vector))\n",
    "print(len(targetList_1415_1819_Vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_tensor = []\n",
    "dfToTensor(inputList_0910_1314_Vector,train_input_tensor)\n",
    "dfToTensor(inputList_1011_1415_Vector,train_input_tensor)\n",
    "dfToTensor(inputList_1112_1516_Vector,train_input_tensor)\n",
    "dfToTensor(inputList_1213_1617_Vector,train_input_tensor)\n",
    "dfToTensor(inputList_1314_1718_Vector,train_input_tensor)\n",
    "\n",
    "test_input_tensor= []\n",
    "dfToTensor(inputList_1415_1819_Vector,test_input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_tensor = []\n",
    "dfToTensor_forTarget(targetList_0910_1314_Vector,train_target_tensor)\n",
    "dfToTensor_forTarget(targetList_1011_1415_Vector,train_target_tensor)\n",
    "dfToTensor_forTarget(targetList_1112_1516_Vector,train_target_tensor)\n",
    "dfToTensor_forTarget(targetList_1213_1617_Vector,train_target_tensor)\n",
    "dfToTensor_forTarget(targetList_1314_1718_Vector,train_target_tensor)\n",
    "\n",
    "test_target_tensor = []\n",
    "dfToTensor_forTarget(targetList_1415_1819_Vector,test_target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "710\n",
      "710\n",
      "110\n",
      "110\n"
     ]
    }
   ],
   "source": [
    "print(len(train_input_tensor))\n",
    "print(len(train_target_tensor))\n",
    "print(len(test_input_tensor))\n",
    "print(len(test_target_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuronalNetVector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluation():\n",
    "    def __init__(self, net, n_epoch):\n",
    "        self.net = net\n",
    "        self.n_epoch = n_epoch\n",
    "        self.criterion = nn.L1Loss()\n",
    "        #self.criterion = nn.MSELoss()\n",
    "        self.optimizer = torch.optim.SGD(net.parameters(), lr = 0.001, momentum = 0.9)\n",
    "        #self.optimizer = torch.optim.Adam(net.parameters(), lr = 0.001)\n",
    "        \n",
    "    def train(self, input_vector, target_vector):\n",
    "        for epoch in range(n_epoch):\n",
    "            running_loss = 0.0\n",
    "            for i in range(len(input_vector)):\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.net(input_vector[i])\n",
    "                loss = self.criterion(outputs, target_vector[i])\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                if i % 710 == 709:\n",
    "                    print(running_loss/ 710)\n",
    "        print('Finished Training')\n",
    "    \n",
    "    def test(self, input_vector, target_vector):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for i in range(len(input_vector)):\n",
    "                outputs = self.net(input_vector[i])\n",
    "                if(torch.argmax(outputs) == torch.argmax(target_vector[i])):\n",
    "                    correct = correct+1\n",
    "        accuracy = correct/len(input_vector)\n",
    "        return(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4046427330762987\n",
      "0.3683101150607297\n",
      "0.36225052565163246\n",
      "0.36088157616553435\n",
      "0.3603447662671308\n",
      "0.36006324656102895\n",
      "0.3598906072857485\n",
      "0.35977248544803664\n",
      "0.35968413727836196\n",
      "0.35961501686542535\n",
      "0.3595572266590423\n",
      "0.3595063399333856\n",
      "0.3594597779950626\n",
      "0.359415951575024\n",
      "0.3593743714890287\n",
      "0.35933324275939293\n",
      "0.3592914548956375\n",
      "0.35924973429550056\n",
      "0.3592070347855805\n",
      "0.3591642839366127\n",
      "0.3591192729027529\n",
      "0.3590668742375528\n",
      "0.3590079353207626\n",
      "0.35894320445512573\n",
      "0.35887389646884943\n",
      "0.35879707398942257\n",
      "0.3587170766957008\n",
      "0.3586321883909411\n",
      "0.35854319441011806\n",
      "0.35845311575472716\n",
      "Finished Training\n",
      "0.4727272727272727\n",
      "0.46056338028169014\n",
      "0.427222695778793\n",
      "0.39732518111631066\n",
      "0.36875699002518725\n",
      "0.3627433406004623\n",
      "0.3612649844537936\n",
      "0.3606688057320023\n",
      "0.36036031690864545\n",
      "0.36017175424895087\n",
      "0.36004405328268746\n",
      "0.3599513645954438\n",
      "0.35988026996371275\n",
      "0.359822927333184\n",
      "0.3597744446517228\n",
      "0.359731880194673\n",
      "0.3596933885850837\n",
      "0.3596571030733775\n",
      "0.3596232753539389\n",
      "0.35958981188783984\n",
      "0.35955590649265035\n",
      "0.3595208660702181\n",
      "0.3594868213554826\n",
      "0.3594502133086791\n",
      "0.35941221829522985\n",
      "0.35937753141707907\n",
      "0.35933943020241693\n",
      "0.3592962421114091\n",
      "0.3592460278076839\n",
      "0.3591866730772692\n",
      "0.35911521955405745\n",
      "0.3590297461580798\n",
      "Finished Training\n",
      "0.4727272727272727\n",
      "0.46056338028169014\n",
      "0.4457518902462973\n",
      "0.44415639840381244\n",
      "0.44382153820823617\n",
      "0.4435836720214763\n",
      "0.4433463693084851\n",
      "0.44303276400331043\n",
      "0.4426395297050476\n",
      "0.4421305512458506\n",
      "0.4415045866664027\n",
      "0.4406916642692727\n",
      "0.4395941461685678\n",
      "0.43756827506381024\n",
      "0.40587738169960574\n",
      "0.3616568094985166\n",
      "0.35097984458972836\n",
      "0.34534663758680784\n",
      "0.34212186770119446\n",
      "0.34003134732914825\n",
      "0.3383422184038411\n",
      "0.3367944580602502\n",
      "0.3351817001437988\n",
      "0.3337374317885444\n",
      "0.3326546611267542\n",
      "0.33178220090214666\n",
      "0.3310562981584996\n",
      "0.3304024452028223\n",
      "0.32985527859268543\n",
      "0.3293772937980516\n",
      "0.32915557679725865\n",
      "0.3289982436200528\n",
      "Finished Training\n",
      "0.4727272727272727\n",
      "0.5126760563380282\n",
      "0.4216670390795654\n",
      "0.38152404284813035\n",
      "0.3636762302236887\n",
      "0.35979456242623176\n",
      "0.3576226929926377\n",
      "0.35558351738077937\n",
      "0.3534157586659795\n",
      "0.3509216549082858\n",
      "0.34786166524081413\n",
      "0.34452683875962437\n",
      "0.3414065246370234\n",
      "0.3390367334827533\n",
      "0.3373082534430285\n",
      "0.3360409488076757\n",
      "0.33506468041316284\n",
      "0.33437980779639015\n",
      "0.3337069714849052\n",
      "0.33313757855046916\n",
      "0.3324910758025482\n",
      "0.33197969507087044\n",
      "0.33131744151324843\n",
      "0.33074765034233333\n",
      "0.33020572432397166\n",
      "0.32948412808170974\n",
      "0.32880551554305654\n",
      "0.32800198912865547\n",
      "0.32730392376039275\n",
      "0.3268567824596779\n",
      "0.3262714769892745\n",
      "0.3256599666859079\n",
      "Finished Training\n",
      "0.4909090909090909\n",
      "0.5225352112676056\n",
      "0.44804427082269965\n",
      "0.4446662457476199\n",
      "0.4444233899804908\n",
      "0.4443441676421904\n",
      "0.44431018430582236\n",
      "0.4442828991043736\n",
      "0.4442529241803666\n",
      "0.4442296066754301\n",
      "0.4442078047654998\n",
      "0.4441856001884165\n",
      "0.4441674976281717\n",
      "0.4441330665433911\n",
      "0.444103297423309\n",
      "0.44406361693227797\n",
      "0.4440152585086688\n",
      "0.44398288756189214\n",
      "0.44393548361012636\n",
      "0.4439006229521523\n",
      "0.44381940784588664\n",
      "0.4437163688767124\n",
      "0.44361071935002233\n",
      "0.4434297400880867\n",
      "0.44323123076432186\n",
      "0.4427774642554807\n",
      "0.4422188889392665\n",
      "0.44154531317697443\n",
      "0.44053325119992376\n",
      "0.4217528373422757\n",
      "0.37382153630860043\n",
      "0.3622422823627909\n",
      "Finished Training\n",
      "0.4727272727272727\n",
      "0.4619718309859155\n",
      "0.4267589562690594\n",
      "0.37189539349588735\n",
      "0.36371307280150317\n",
      "0.3619798804190613\n",
      "0.36124482125769997\n",
      "0.36083947441642744\n",
      "0.3605823800466148\n",
      "0.3604043519885136\n",
      "0.36027383674653524\n",
      "0.3601739992109024\n",
      "0.3600956142635854\n",
      "0.3600324986231038\n",
      "0.3599807359132916\n",
      "0.3599377339250313\n",
      "0.3599007802443929\n",
      "0.35986955025374273\n",
      "0.3598427355832286\n",
      "0.3598194732158415\n",
      "0.3597990577215147\n",
      "0.35978100285399545\n",
      "0.35976492899376583\n",
      "0.3597505238985422\n",
      "0.3597375467626542\n",
      "0.3597257781975786\n",
      "0.35971505393261516\n",
      "0.3597052218192639\n",
      "0.3596961618864536\n",
      "0.35968780294861835\n",
      "0.35968005017345656\n",
      "0.35967281650747457\n",
      "Finished Training\n",
      "0.4727272727272727\n",
      "0.46056338028169014\n",
      "0.4277397234884786\n",
      "0.37739295817544344\n",
      "0.36443972742674025\n",
      "0.36206262969970876\n",
      "0.3611799153077796\n",
      "0.360734267640272\n",
      "0.3604694682091203\n",
      "0.36029580291408725\n",
      "0.36017277625928407\n",
      "0.360081532400263\n",
      "0.36001112524720613\n",
      "0.35995509256144304\n",
      "0.35990931741044996\n",
      "0.3598712782518434\n",
      "0.3598390521666178\n",
      "0.35981132596209997\n",
      "0.35978715626959684\n",
      "0.3597658189714587\n",
      "0.3597467627737246\n",
      "0.35972956174902376\n",
      "0.35971391501857586\n",
      "0.3596995317185181\n",
      "0.359686173708707\n",
      "0.3596736641410962\n",
      "0.35966184755326935\n",
      "0.35965058791945137\n",
      "0.3596397723217017\n",
      "0.3596293111082812\n",
      "0.359619099287782\n",
      "0.3596090689776174\n",
      "Finished Training\n",
      "0.4727272727272727\n",
      "0.46056338028169014\n",
      "0.43771386910492266\n",
      "0.39711121247792747\n",
      "0.36651921125840475\n",
      "0.3622347691678852\n",
      "0.3611045150662391\n",
      "0.3606153460137078\n",
      "0.36034748778443365\n",
      "0.36017885733009136\n",
      "0.3600626364871356\n",
      "0.3599774424631454\n",
      "0.35991167342654234\n",
      "0.3598584919672411\n",
      "0.35981397257225284\n",
      "0.35977525765507473\n",
      "0.35974040987192435\n",
      "0.35970790087794147\n",
      "0.35967645587046637\n",
      "0.3596448728831563\n",
      "0.3596119986430385\n",
      "0.3595763889713461\n",
      "0.3595362962220954\n",
      "0.3594892913328757\n",
      "0.35943078503239606\n",
      "0.3593493232520657\n",
      "0.3592408993409966\n",
      "0.35909243125843276\n",
      "0.35890411142086953\n",
      "0.35864812804126633\n",
      "0.3583045323921205\n",
      "0.3579062962681515\n",
      "Finished Training\n",
      "0.4727272727272727\n",
      "0.46056338028169014\n",
      "0.4246672407842018\n",
      "0.38757825475054936\n",
      "0.36752688272767636\n",
      "0.3635036596429492\n",
      "0.36212602699260327\n",
      "0.36145399792025734\n",
      "0.36105937978789526\n",
      "0.3608000971966495\n",
      "0.3606169382716969\n",
      "0.3604810227525364\n",
      "0.36037670310078496\n",
      "0.36029517752982215\n",
      "0.36022401025475737\n",
      "0.36016627824563685\n",
      "0.3601183582133603\n",
      "0.3600778117559774\n",
      "0.3600431736171428\n",
      "0.360013254571717\n",
      "0.3599871521972274\n",
      "0.3599641398082698\n",
      "0.35994353443998534\n",
      "0.3599249510807852\n",
      "0.3599082475730169\n",
      "0.3598932068606366\n",
      "0.3598796580758748\n",
      "0.3598673836625394\n",
      "0.35985613902635916\n",
      "0.35984580742747696\n",
      "0.35983627543482133\n",
      "0.35982745058624843\n",
      "Finished Training\n",
      "0.4727272727272727\n",
      "0.46056338028169014\n",
      "0.42635130002884797\n",
      "0.38765443347027184\n",
      "0.36584827186782437\n",
      "0.36203863135556213\n",
      "0.3609143984908731\n",
      "0.36040620147591335\n",
      "0.3601197943848246\n",
      "0.3599364860213991\n",
      "0.35980705658326245\n",
      "0.3597080689525119\n",
      "0.35962780237685327\n",
      "0.35955834552493676\n",
      "0.3594966523218443\n",
      "0.35943391165556454\n",
      "0.35937634030840365\n",
      "0.3593202281119019\n",
      "0.3592625096780939\n",
      "0.3592052090136814\n",
      "0.3591429398667106\n",
      "0.35907135321766703\n",
      "0.35898641394898934\n",
      "0.3588973773939978\n",
      "0.3588001533492725\n",
      "0.35870284610936315\n",
      "0.35859649911788294\n",
      "0.35847251245339945\n",
      "0.3583286067354006\n",
      "0.35817868106546163\n",
      "0.35800310589301576\n",
      "0.35778846594164115\n",
      "Finished Training\n",
      "0.4727272727272727\n",
      "0.46056338028169014\n",
      "0.4288798796458983\n",
      "0.3903217319871338\n",
      "0.3660529831895756\n",
      "0.36197516839133703\n",
      "0.3608712054665093\n",
      "0.36039592576666124\n",
      "0.36013386441951095\n",
      "0.3599656172789053\n",
      "0.35984455461158227\n",
      "0.35974938236396853\n",
      "0.3596686551484151\n",
      "0.35959717891540377\n",
      "0.3595340160301272\n",
      "0.35947270497807005\n",
      "0.3594095034083707\n",
      "0.3593424843473001\n",
      "0.35926797372855673\n",
      "0.35918486108176023\n",
      "0.35910352717665583\n",
      "0.3590087499422234\n",
      "0.35890037472673797\n",
      "0.35877483927776205\n",
      "0.3586429662222453\n",
      "0.35851170357059475\n",
      "0.3583817996337931\n",
      "0.35826345343997623\n",
      "0.35814003319231247\n",
      "0.35800524234358344\n",
      "0.35784102881856766\n",
      "0.35763814916499675\n",
      "Finished Training\n",
      "0.4727272727272727\n",
      "0.46056338028169014\n",
      "0.4265994373026868\n",
      "0.3707142732219285\n",
      "0.36288438411882734\n",
      "0.36133694542872274\n",
      "0.36071901838030623\n",
      "0.3603975996085736\n",
      "0.3602045578534261\n",
      "0.36007691596653185\n",
      "0.35998706002657616\n",
      "0.3599204468133579\n",
      "0.3598696194581045\n",
      "0.35982928495331945\n",
      "0.35979657526740194\n",
      "0.35976960393125423\n",
      "0.3597469323089753\n",
      "0.35972758616523415\n",
      "0.35971078618094504\n",
      "0.359696072405392\n",
      "0.359683050371719\n",
      "0.359671399078575\n",
      "0.35966098215802816\n",
      "0.35965153159600327\n",
      "0.35964286807083384\n",
      "0.359635016112718\n",
      "0.35962777353299363\n",
      "0.35962107834814144\n",
      "0.3596147976550054\n",
      "0.35960892946018697\n",
      "0.35960335821722195\n",
      "0.3595981373650429\n",
      "Finished Training\n",
      "0.4727272727272727\n",
      "0.46056338028169014\n",
      "0.4372216170522529\n",
      "0.4126447657988945\n",
      "0.3783385484677766\n",
      "0.36586230336798364\n",
      "0.36271816070855295\n",
      "0.3615283137649289\n",
      "0.36090496351278056\n",
      "0.36052341784961317\n",
      "0.3602650014212203\n",
      "0.36008054839192305\n",
      "0.3599306628573111\n",
      "0.3598035390370333\n",
      "0.35968459417600174\n",
      "0.35955669354160386\n",
      "0.3594167864154151\n",
      "0.35925764544771377\n",
      "0.3590485975879464\n",
      "0.35874877614723294\n",
      "0.35822563384047257\n",
      "0.3572024483993767\n",
      "0.35513260191001855\n",
      "0.3525058903698297\n",
      "0.34963541645417223\n",
      "0.34656643104271606\n",
      "0.34385268109583883\n",
      "0.341877615031335\n",
      "0.34040781108229284\n",
      "0.33922920809239865\n",
      "0.33831363327346414\n",
      "0.337536904880071\n",
      "Finished Training\n",
      "0.5\n",
      "0.5028169014084507\n",
      "0.4259667402212049\n",
      "0.379269506283511\n",
      "0.3644802310572167\n",
      "0.36181842528658276\n",
      "0.3608927343628053\n",
      "0.3604459258293356\n",
      "0.3601884252962439\n",
      "0.36002297067359407\n",
      "0.3599070898698666\n",
      "0.3598193275553817\n",
      "0.359751625627153\n",
      "0.3596955675352876\n",
      "0.35964835879280843\n",
      "0.35960586564177055\n",
      "0.3595666645027514\n",
      "0.35952940657793864\n",
      "0.3594911063894334\n",
      "0.35945062084601576\n",
      "0.3594092877498909\n",
      "0.35936572754521673\n",
      "0.35931827461580995\n",
      "0.35926554394456167\n",
      "0.3592051830157767\n",
      "0.3591340190979458\n",
      "0.359047722049825\n",
      "0.3589446542592139\n",
      "0.35882110001111406\n",
      "0.358669606796775\n",
      "0.3584762425939507\n",
      "0.3582295059811813\n",
      "Finished Training\n",
      "0.4727272727272727\n",
      "0.46056338028169014\n",
      "0.4372449195301029\n",
      "0.40697500315350543\n",
      "0.37080657983093823\n",
      "0.3628146599276437\n",
      "0.36100974095004373\n",
      "0.3602496403922897\n",
      "0.3598016395561592\n",
      "0.3594594259935407\n",
      "0.3591431364073918\n",
      "0.35883747680968237\n",
      "0.3585359856901561\n",
      "0.3582297866283876\n",
      "0.35789255989341007\n",
      "0.35740263596885774\n",
      "0.35678547423517853\n",
      "0.35595839401729357\n",
      "0.3548051940900831\n",
      "0.3529448751364951\n",
      "0.350548545324558\n",
      "0.3479222398975537\n",
      "0.3450475534620621\n",
      "0.3424226225698938\n",
      "0.34028478143055835\n",
      "0.33855592858211514\n",
      "0.337168030942056\n",
      "0.3359425205231216\n",
      "0.3348429776216119\n",
      "0.33377617489264255\n",
      "0.3328814738135751\n",
      "0.332099841394183\n",
      "Finished Training\n",
      "0.4909090909090909\n",
      "0.5056338028169014\n",
      "0.4364077995780488\n",
      "0.3901878313528715\n",
      "0.3662222958694976\n",
      "0.3625904007764815\n",
      "0.3614371146352516\n",
      "0.3608914038068012\n",
      "0.3605792415728578\n",
      "0.36037847511650295\n",
      "0.36023993590989073\n",
      "0.3601391661038246\n",
      "0.36006235364837685\n",
      "0.360002139927281\n",
      "0.3599540750692819\n",
      "0.3599149207422917\n",
      "0.35988246719541106\n",
      "0.3598551827167387\n",
      "0.35983194983384065\n",
      "0.35981195280110917\n",
      "0.3597945714547353\n",
      "0.3597793314614285\n",
      "0.35976586475482963\n",
      "0.3597538872140778\n",
      "0.35974316334139245\n",
      "0.35973351720787844\n",
      "0.35972478912812383\n",
      "0.35971685620506333\n",
      "0.35970961299371546\n",
      "0.35970297306481214\n",
      "0.3596968601337284\n",
      "0.35969121554179945\n",
      "Finished Training\n",
      "0.4727272727272727\n",
      "0.46056338028169014\n",
      "0.43423505555576003\n",
      "0.39294086344225304\n",
      "0.3665237080230391\n",
      "0.3623548949418428\n",
      "0.3612091183913922\n",
      "0.3607101727345675\n",
      "0.36043863212563115\n",
      "0.3602704228184387\n",
      "0.36015695891904415\n",
      "0.36007571110907804\n",
      "0.3600148956242446\n",
      "0.3599677975432622\n",
      "0.3599303244244997\n",
      "0.359899841898094\n",
      "0.3598745981697139\n",
      "0.35985336869279283\n",
      "0.35983527577199076\n",
      "0.35981968306466844\n",
      "0.3598061161092303\n",
      "0.35979420442678084\n",
      "0.359783667715225\n",
      "0.35977428747447404\n",
      "0.3597658779268275\n",
      "0.3597583023491269\n",
      "0.3597514393505177\n",
      "0.35974519861996035\n",
      "0.3597394973032545\n",
      "0.35973426692184424\n",
      "0.3597294553237324\n",
      "0.3597250123485482\n",
      "Finished Training\n",
      "0.4727272727272727\n",
      "0.46056338028169014\n",
      "0.44514441670666277\n",
      "0.4446133981288319\n",
      "0.4443736172477964\n",
      "0.4440795316662587\n",
      "0.4437609140302094\n",
      "0.4433433023556857\n",
      "0.44282473863010674\n",
      "0.44218464875724955\n",
      "0.4413738269621218\n",
      "0.4401909556817001\n",
      "0.4388858612994073\n",
      "0.4372176590834705\n",
      "0.4351308676663419\n",
      "0.4331154680220594\n",
      "0.43120752225406994\n",
      "0.429467854613412\n",
      "0.42798855822913767\n",
      "0.4267748969672641\n",
      "0.42580987922093033\n",
      "0.4250813033539986\n",
      "0.4244300185920815\n",
      "0.42389890422296883\n",
      "0.4235060093992244\n",
      "0.42306992485045297\n",
      "0.4228384300831006\n",
      "0.4224100697707886\n",
      "0.4219578358014677\n",
      "0.4215857678027353\n",
      "0.42128317892041284\n",
      "0.4210958919387721\n",
      "Finished Training\n",
      "0.3090909090909091\n",
      "0.2915492957746479\n",
      "0.4449206178037214\n",
      "0.44428271126579233\n",
      "0.42601229941970864\n",
      "0.37319163070994915\n",
      "0.3623799889788489\n",
      "0.36061884609537204\n",
      "0.35991883290759213\n",
      "0.35950916729100013\n",
      "0.35918416109045825\n",
      "0.35887784121454763\n",
      "0.3585532937793913\n",
      "0.35816365040048387\n",
      "0.3576843332303645\n",
      "0.35704256020910696\n",
      "0.3561759161290437\n",
      "0.3548357990390173\n",
      "0.35308828244037344\n",
      "0.3508665675526929\n",
      "0.3480738280174948\n",
      "0.3448896498048116\n",
      "0.34164023045834\n",
      "0.33888148745179725\n",
      "0.336746975366832\n",
      "0.3349485807324855\n",
      "0.3335869922608293\n",
      "0.33245955657655574\n",
      "0.3315172819398668\n",
      "0.3306288472494233\n",
      "0.32984591117356354\n",
      "0.32905765596292713\n",
      "Finished Training\n",
      "0.4909090909090909\n",
      "0.5183098591549296\n",
      "0.41521265238103733\n",
      "0.3734199115198145\n",
      "0.3633437855970557\n",
      "0.3614574853357649\n",
      "0.3607464692541764\n",
      "0.3603815979841188\n",
      "0.36015994410765584\n",
      "0.36000932373530864\n",
      "0.35989819898951575\n",
      "0.3598104712971326\n",
      "0.35973778951334084\n",
      "0.3596745374224206\n",
      "0.3596167202638659\n",
      "0.3595621858014157\n",
      "0.35950857949688225\n",
      "0.35945348288750106\n",
      "0.3593962571803364\n",
      "0.3593348709222217\n",
      "0.3592657678889292\n",
      "0.3591854023287457\n",
      "0.3590948407981527\n",
      "0.3589918968397038\n",
      "0.3588710051718297\n",
      "0.3587306970709149\n",
      "0.3585677496939088\n",
      "0.35839510899065125\n",
      "0.35820970405153535\n",
      "0.3580220019977461\n",
      "0.3578167038024141\n",
      "0.3575994250134331\n",
      "Finished Training\n",
      "0.4727272727272727\n",
      "0.46056338028169014\n"
     ]
    }
   ],
   "source": [
    "accuracy_train = {}\n",
    "accuracy_test = {}\n",
    "for i in range(20):\n",
    "    test_eval = Evaluation(NeuronalNetVector(),30)\n",
    "    test_eval.train(train_input_tensor,train_target_tensor)\n",
    "    test_result = test_eval.test(test_input_tensor,test_target_tensor)\n",
    "    accuracy_test[i] = test_result\n",
    "    train_test_result = test_eval.test(train_input_tensor,train_target_tensor)\n",
    "    accuracy_train[i] = train_test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_tuple = sorted(accuracy_test.items())\n",
    "train_tuple = sorted(accuracy_train.items())\n",
    "\n",
    "test_x, test_y = zip(*test_tuple)\n",
    "test_y = [1-val for val in test_y]\n",
    "train_x, train_y = zip(*train_tuple)\n",
    "train_y = [1-val for val in train_y]\n",
    "\n",
    "test_line = plt.plot(test_x, test_y, label='Testdaten')\n",
    "trainings_line = plt.plot(train_x , train_y , label = 'Trainingsdaten')\n",
    "\n",
    "plt.xlabel(\"Modellkomplexitaet\")\n",
    "plt.ylabel(\"Fehler\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4727272727272727\n"
     ]
    }
   ],
   "source": [
    "#Quantitative Evaluierung \n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_input_tensor)) :\n",
    "        outputs = net(test_input_tensor[i])\n",
    "        if (torch.argmax(outputs) == torch.argmax(test_target_tensor[i])):\n",
    "            correct = correct+1\n",
    "print(correct / len(test_input_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    }
   ],
   "source": [
    "a = 0\n",
    "for data in test_loader:\n",
    "    a = a+1\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt \n",
    "test_tuple = sorted(a.items())\n",
    "train_tuple = sorted(accuracy_dict_train.items())\n",
    "\n",
    "test_x, test_y = zip(*test_tuple)\n",
    "test_y = [1-val for val in test_y]\n",
    "train_x, train_y = zip(*train_tuple)\n",
    "train_y = [1-val for val in train_y]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
